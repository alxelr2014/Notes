\chapter{Multivariable Calculus}
\thispagestyle{headings}
\section{Linear Algebra}
\subsection{Vector Spaces}

\begin{definition}[Normed vector space]
    Let \(V\) be a vector space. A \textbf{norm} is a real valued function \(\norm: V \to \Reals\) which has the following properties
    \begin{enumerate}
        \item \(\forall x \in V, \; \norm[x] > 0\).
        \item \(\norm[x] = 0 \implies x = 0\).
        \item \(\forall x \in V \; \forall \alpha \in \Field, \; \norm[\alpha x] = \abs[\alpha] \norm[x]\).
        \item \(\forall x,y \in V \; \norm[x+y] \leq \norm[x] + \norm[y]\).
    \end{enumerate}
\end{definition}

Each normed vector space induces a metric space \(\metricSpace{V}{d}\) where \(\func{d}{x,y} = \norm[y - x]\).

\begin{theorem}
    In every normed space \(\normedSpace{V}{\norm}\) we have
    \begin{equation*}
        \abs[ {\norm[v] - \norm[w]}] \leq \norm[v - w]
    \end{equation*}
    Hence the norm is Lipschitz continuous.
\end{theorem}


\begin{definition}
    Assume \(V\) is a vector space and let \(\norm_1, \; \norm_2\) be two norms for \(V\). They are said to be equivalent when
    \begin{equation*}
        \exists c_1,c_2 > 0 \; \forall x : \qquad c_1 \norm[x]_1 \leq \norm[x]_2 \leq c_2 \norm[x]
    \end{equation*}
\end{definition}

To check if the above definition is indeed an equivalence relation, we must show that following:
\begin{description}
    \item [Reflexive] \(\norm_1 \sim \norm_1\).
    \item [Symmetric] \(\norm_1 \sim \norm_2 \implies \norm_2 \sim \norm_1\).
    \item [Transitive] \( \norm_1 \sim \norm_2 , \; \norm_2 \sim \norm_3 \implies \norm_1 \sim \norm_3\).
\end{description}

\begin{remark}
    Equivalent norms induce equivalent metrics, hence they induce the same topology.
\end{remark}

\begin{theorem}
    All norms defined on a finite dimensional vector space \(V\) are equivalent.
\end{theorem}

\begin{proof}
    Let \(\norm\) be an arbitrary norm on \(V\) and \(\{e_1, e_2, \dots , e_n\} \) be a basis of \(V\). Let \(\norm_2\) be \(L_2\)-norm (Euclidean norm). It will suffice to show \(\norm \sim \norm_2\). Let
    \begin{equation*}
        M = \max \! \left( \norm[e_1], \dots , \norm[e_n] \right)
    \end{equation*}
    Take \(x \in V\), writing \(x = \sum_{i = 1}^n {\xi_i e_i}\) we have:
    \begin{equation*}
        \norm[x] = \norm[\sum_{i = i}^n {\xi_i e_i}] \leq \sum_{i = 1}^n \abs{\xi_i} \norm[e_i] \leq M \sqrt{n} \norm[x]_2
    \end{equation*}
    Taking \(c_2 = M \sqrt{n}\) proves the right inequality. For the left inequality we need the following lemma
    \begin{lemma} \label{lm:ContinuityOfNorm}
        If \(V\) is a normed vector space with \(\norm_2\), as defined above, is viewed as metric space \(\metricSpace{V}{\norm_2}\) then \(\norm : V \to \Reals\) is continuous.
    \end{lemma}

    \begin{prooflemma}
        Let \(x_0 \in V\) and \(M\) be defined as above. For any \(\epsilon > 0\) consider \(\delta = \frac{\epsilon}{M \sqrt{n}}\) then if \(\norm[x - x_0]_2 < \delta\)
        \begin{equation*}
            \abs[\norm[x] - \norm{x_0}] \leq \norm[x - x_0] \leq M \sqrt{n} \norm[x - x_0] \leq \epsilon
        \end{equation*}
    \end{prooflemma}

    Now consider the sphere of radius \(r = 1\) centered at \(0\), \(\func{S_1}{0} = S_1 = \{x \in V : \norm[x]_2 = 1\}\). One can show that \(S\) is compact. Therefore, \(\norm[x]\) assumes its minimum on \(S\). Let \( a = \norm[x_0]\) be the minimum. Since \(0 \notin S\) then \(a > 0\). By letting \(y = x / \norm[x]_2 \), we have \(y \in S\) and thus \(a \leq \norm[y]\) which is
    \begin{equation*}
        a \norm[x]_2 \leq \norm[x]
    \end{equation*}
    Taking \(c_1 = a\) proves the theorem.
\end{proof}

\begin{theorem}
    Let \(\normedSpace{V}{\norm}\) be a normed space. The following are equivalent
    \begin{enumerate}
        \item \(V\) is finite dimensional.
        \item every bounded closed set in \(V\) is compact.
        \item the closed unit ball in \(V\) is compact.
    \end{enumerate}
\end{theorem}

%TODO: do the proof, 3 to 1 is the hardest part
\begin{proof}

\end{proof}

\subsection{Linear Maps}
Let \(V\) and \(W\) be a vector spaces over \(\Field\). A map \(T: V \to W\) is \textbf{linear} if
\begin{equation*}
    \func{T}{x + \lambda y} = \func{T}{x} + \lambda \func{T}{y}
\end{equation*}
for all \(x,y \in V\) and \(\lambda \in \Field\).

\begin{definition}
    Let \(\normedSpace{V}{\norm_V}\) and \(\normedSpace{W}{\norm_W}\) be normed spaces then, a linear transformation \(T : V \to W\) is \textbf{bounded} if there exists a constant \(C > 0\) such that
    \begin{equation*}
        \norm[Tv]_W \leq C \norm[v]_V
    \end{equation*}
    for all \(v \in V\).
\end{definition}

\begin{definition}
    If \(\normedSpace{V}{\norm_V},\normedSpace{W}{\norm_W}\) are normed spaces then the \textbf{operator norm} of a linear transformation \(T : V \to W\) is
    \begin{equation*}
        \norm[T] = \sup \left\{\dfrac{\norm[Tv]_W}{\norm[v]_V} \middle| v \neq 0 \right\}
    \end{equation*}
\end{definition}

\begin{theorem}
    Let \(\normedSpace{V}{\norm_V}\) and \(\normedSpace{W}{\norm_W}\) be normed spaces and \(T: V \to W\) be a linear transformation. The following are equivalent
    \begin{enumerate}
        \item \(\norm[T]\) is finite. \label{it:LinearCont1}
        \item \(T\) is bounded. \label{it:LinearCont2}
        \item \(T\) is Lipschitz continuous. \label{it:LinearCont3}
        \item \(T\) is continuous at a point. \label{it:LinearCont4}
        \item \(\sup_{\norm[v]_V = 1} \norm[Tv]_W < \infty\). \label{it:LinearCont5}
    \end{enumerate}
\end{theorem}

\begin{proof}
    %TODO: fix the references
    \cref{it:LinearCont1} \(\Rightarrow\) \cref{it:LinearCont2}: Obviously
    \begin{align*}
        \dfrac{\norm[Tv]_W}{\norm[v]_V} & \leq \norm[T]            \\
        \implies \norm[Tv]_W            & \leq \norm[T] \norm[v]_V
    \end{align*}
    note that if \(v = 0\) then \(Tv = 0\) as well and thus the last inequality holds for all \(v \in V\).

    \cref{it:LinearCont2} \(\Rightarrow\) \cref{it:LinearCont3}:
    \begin{equation*}
        \norm[Tv - Tu]_W = \norm[T(u - v)]_W \leq C \norm[u - v]_V
    \end{equation*}

    \cref{it:LinearCont3} \(\Rightarrow\) \cref{it:LinearCont4}: Trivial.

    \cref{it:LinearCont4} \(\Rightarrow\) \cref{it:LinearCont5}: Let \(T\) be continuous at \(u \in V\). Then there is  a \(\delta > 0 \) such that
    \begin{equation*}
        \norm[v-u] < \delta \implies \norm[Tv - Tu]_W = \norm[T(v-u)]_W < 1
    \end{equation*}
    Now for an arbitrary non-zero \(v\) we have
    \begin{equation*}
        \norm[\left( \dfrac{\delta v}{2\norm[v]_V} + u \right) - u]_V < \delta
    \end{equation*}
    Therefore
    \begin{align*}
         & \norm[\func{T}{\dfrac{\delta v}{2\norm[v]_V}}]_W  < 1         \\
         & \norm[\func{T}{\dfrac{v}{\norm[v]_V}}]_W  < \dfrac{2}{\delta}
    \end{align*}

    \cref{it:LinearCont5} \(\Rightarrow\) \cref{it:LinearCont1}: Let \(v \in V\) be an arbitrary vector. Then
    \begin{align*}
                 & \sup \norm[\func{T}{\dfrac{v}{\norm[v]_V}}]_W < \infty \\
        \implies & \sup \norm[Tv]_W < \infty
    \end{align*}

\end{proof}

\begin{theorem}
    Let \(f : \Reals^n \to \Reals^n\) linear transformation is invertible if and only if there exists a \(c\) such that:
    \begin{equation*}
        c \norm[x] \leq \norm[\func{f}{x}]
    \end{equation*}
\end{theorem}

\begin{proof}
    A linear transformation \(f: \Reals^n \to \Reals^n\) is one-to-one if and only if it is surjective because \(\dim \Image f + \dim \ker f = n\). Hence, we only need to show that \(f\) is one-to-one.
\end{proof}

{\Large\textbf{Exercises}}
\begin{enumerate}
    \item Show that for a linear transformation \(T\), \(\norm[T] = \sup_{\norm[v]_V \leq 1} \norm[Tv]_W\).
\end{enumerate}
\newpage

\section{Derivative}
Let \(f: U \subset \Reals^n \to \Reals^m\) where \(U\) is open. Then \(f\) is differentiable at \(x_0\) when a linear transformation \(T : \Reals^n \to \Reals^m\) such that
\begin{equation*}
    \lim_{\norm[h] \to 0} \dfrac{\norm[\func{f}{x_0 + h} - \func{f}{x_0} - \func{T}{h}]}{\norm[h]}= 0
\end{equation*}
Usually, \(T\) is represented by \(\func{f'}{x_0}\).

\begin{proposition}
    Assume \(f: U \subset \Reals^n \to \Reals^m\) is differentiable at \(x_0\) and let \(u \in \Reals^n\) then
    \begin{equation*}
        \lim_{t \to 0} \dfrac{\func{f}{x_0 + tu} - \func{f}{x_0}}{t} = \func{f'}{x_0} \cdot u
    \end{equation*}
\end{proposition}

\begin{definition}[Partial derivative]
    define

\end{definition}

\begin{proposition}
    If \(f\) is differentiable then its partial derivatives exist.
\end{proposition}

\begin{proposition}
    \(f : U \subset \Reals^n \to \Reals^m\) is differentiable at \(x_0\) if and only if every component is differentiable at \(x_0\).
\end{proposition}

\begin{theorem}
    \(f : U \subset \Reals^n \to \Reals^m\) has all of its partial derivative and they're continuous then \(f\) is differentiable.
\end{theorem}