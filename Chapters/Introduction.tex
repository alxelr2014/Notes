\chapter{Introduction to Lattice}
\begin{definition}
    Let \(b_1, \dots, b_n \in \Reals^m\) be \(n\) linearly independent vectors. The \textbf{lattice} generated by these vectors is denoted as \(\func{\calL}{b_1, \dots, b_n}\) and 
    \begin{equation*}
        \func{\calL}{b_1, \dots, b_n} = \set< \sum_{i = 1}^n x_i b_i>{x_i \in \Integers}
    \end{equation*}
    If we let \(B = \begin{bmatrix}
        b_1 & b_2 & \dots & b_n
    \end{bmatrix}\), then  
    \begin{equation*}
        \func{\calL}{B} = \set<Bx>{x \in \Integers^n}
    \end{equation*}
    If \(n = m\), then the lattice is said to be \textbf{full rank}. \(m\) is the dimension and \(n\) is the rank of the lattice.
\end{definition}

-- the case where \(\func{\calL}{B}\) is not a lattice.
\section{Description of lattices}
\subsection{Algebraic description}
\begin{definition}
    A matrix \(U \in \Integers^{n \times n}\) is \textbf{unimodular} if \(\abs{\det U} = 1\). 
\end{definition}
\begin{proposition}
    The unimodular matrices form a group under matrix multiplication.
\end{proposition}
\begin{proof}
    Clearly, \(I\) is a unimodular matrix and is the identity element of the group. By definition, a unimodular matrix \(U\) is invertible and \(\abs{\det U^{-1}} = 1\). Also, note that 
    \begin{equation*}
        U^{-1} = \frac{1}{\det U} \func{\adjoint}{U}
    \end{equation*}
    where the adjugate matrix \(\func{\adjoint}{U}\) is an integer matrix. Thus, \(U^{-1} \in \Integers^{n}\). The associativity follows from the associativity of matrix multiplication.
\end{proof}

\begin{theorem}\label{thm:BasisEquivalencyUptoUnimodular}
    Two full rank matrix \(B,B' \in \Reals^n\) produce the same lattice if and only if there exists a unimodular matrix \(U\) such that \(B' = BU\).
\end{theorem}

\subsection{Geometric description}
\begin{definition}
    Suppose \(b_1, \dots, b_n \in \Reals^m\) are linearly independent. The \textbf{fundamental parallelopiped} of these vectors is 
    \begin{equation*}
        \func{\calP}{b_1,\dots, b_n} = \set<\sum_{i=1}^n x_i b_i>{x_i \in \clop{0}{1}}
    \end{equation*}
\end{definition}

\begin{theorem}
    Suppose \(\Lambda\) is a full rank \(n\)-dimensional lattice and \(b_1, \dots, b_n \in \Reals^n\) are linearly independent vectors in \(\Lambda\). Then \(b_1, \dots, b_n\) are a basis for \(\Lambda\) if and only if 
    \begin{equation*}
        \Lambda \cap \func{\calP}{b_1,\dots, b_n} = \set{0}
    \end{equation*}
\end{theorem}

\section{Determinant of lattice}
\begin{definition}
    Let \(\Lambda\) be a lattice generated basis \(B\). The \textbf{determinant} of \(\Lambda\) is the volume of fundamental parallelopiped of \(B\).
    \begin{equation*}
        \det \Lambda = \func{\vol}{\func{\calP}{B}}
    \end{equation*}
    It can be shown that \(\func{\vol}{\func{\calP}{B}} = \sqrt{\det B^T B}\). To show that this definition is well-defined, we must prove that for any basis two \(B, B'\), the volumes of fundamental parallelopipeds are equal. Since, \(B\) and \(B'\) generate the same lattice, by \ref{thm:BasisEquivalencyUptoUnimodular}, there exists a unimodular matrix \(U\) such that \(B' = BU\).
    \begin{align*}
        \func{\vol}{\func{\calP}{B'}} &= \sqrt{\det B^{'T}B'}\\
        &= \sqrt{\det (BU)^T BU}\\
        &= \sqrt{\det U^T B^T B U}\\
        &= \sqrt{\det U^T \det B^T B \det U}\\
        &= \sqrt{(\det U)^2 \det B^T B}\\
        &= \sqrt{\det B^T B} = \func{\vol}{\func{\calP}{B}}
    \end{align*}
    which was what was wanted. 
\end{definition}

Intuitively, the \(\det \Lambda\) is inversely proportional to its density. 

\begin{remark}
    In mathematical analysis, the volume -- or length or area -- of a set is measured with \textit{measures}. The exact definition of a measure is beyond the scope this text, however, we will almost always use the \textit{lebesgue measure}, unless stated otherwise. Measures can be defined on any set, and hence the measure of set may not depend on a particular metric. As a result, we are able to consider the same space with the same measure under different metrics or norms without affecting the measure. 
\end{remark}
\section{Gram-Schmidt}
In Gram-Schmidt procedure, a set of linearly independent vectors \(b_1, \dots, b_n\) are transformed into a set of orthogonal vectors \(b_1^{\ast}, \dots, b_n^{\ast}\).
\begin{equation*}
    b_i^{\ast} = b_i - \sum_{j = 1}^{i - 1} \dfrac{\angleBracket{b_i,b_j^{\ast}}}{\angleBracket{b_j^{\ast}, b_j^{\ast}}} b_j^{\ast} = b_i - \sum_{j = 1}^{i - 1} u_{i,j} b_j^{\ast}
\end{equation*}
with \(b_1^{\ast} = b_1\).
\begin{proposition}
    \ 
    \begin{enumerate}
        \item For all \(i \neq j\), \(\angleBracket{b_i^{\ast},b_j^{\ast}} = 0\).
        \item For all \(i > j\), \(\angleBracket{b_i^{\ast}, b_j} = 0\).
        \item For all \(i\), \(\vspan \set{b_1, \dots, b_i} = \vspan \set{b_1^{\ast}, \dots, b_i^{\ast}}\).
        \item If \(B = \begin{bmatrix}
            b_1 & \dots & b_n
        \end{bmatrix}\) and \(B^{\ast} = \begin{bmatrix}
            b_1^{\ast} & \dots & b_n^{\ast}
        \end{bmatrix}\), then 
        \begin{equation*}
            B = B^{\ast} \begin{bmatrix}
                1 & u_{2,1} & \dots & u_{n,1}\\
                0 & 1 & \dots & u_{n,2}\\
                \vdots& \vdots& \ddots& \vdots \\
                0 & 0 & \dots & 1
            \end{bmatrix}
        \end{equation*}
    \end{enumerate}
\end{proposition}
\begin{lemma}
    If we apply the Gram-Schmidt procedure to \(B \in \Reals^{m \times n}\) and get \(B^{\ast} \in \Reals^{m \times n}\), then 
    \begin{equation*}
        \det B^T B = \prod_{i = 1}^n \norm{b_i^{\ast}}^2
    \end{equation*}
\end{lemma}
\begin{proof}
    Note that,
    \begin{equation*}
        B^{\ast} \begin{bmatrix}
            1 & u_{2,1} & \dots & u_{n,1}\\
            0 & 1 & \dots & u_{n,2}\\
            \vdots& \vdots& \ddots& \vdots \\
            0 & 0 & \dots & 1 
        \end{bmatrix} = \begin{bmatrix}
            \dfrac{b_1^{\ast}}{\norm{b_1^{\ast}}} & \dots & \dfrac{{b_1^{\ast}}}{\norm{b_n^{\ast}}}
        \end{bmatrix}
            \begin{bmatrix}
            \norm{b_1^{\ast}} & u_{2,1}\norm{b_1^{\ast}} & \dots & u_{n,1}\norm{b_1^{\ast}}\\
            0 & \norm{b_2^{\ast}} & \dots & u_{n,2}\norm{b_2^{\ast}}\\
            \vdots& \vdots& \ddots& \vdots \\
            0 & 0 & \dots & \norm{b_n^{\ast}}
        \end{bmatrix}
    \end{equation*}
    Let \(B^{\ast'}\) be the orthonormal Gram-Schmidt matrix as calculated above and \(U'\) its corresponding upper triangular matrix.
    \begin{align*}
        \det B^T B &= \func{\det}{ (B^{\ast}U)^T B^{\ast} U}\\
        &= \func{\det}{(U')^T (B^{\ast'})^T B^{\ast'} U'}\\
        &= \det U' \det (B^{\ast'})^T B^{\ast'} \det U'\\
        &= \prod_{i = 1}^n \norm{b_i^{\ast}}^2 \det (B^{\ast'})^T B^{\ast'}
    \end{align*}
    Behold, the columns of \(B^{\ast'}\) are orthonormal therefore, \((B^{\ast'})^T B^{\ast'} = I_n\) and hence 
    \begin{equation*}
        \det B^T B = \prod_{i = 1}^n \norm{b_i^{\ast}}^2
    \end{equation*}
    which was what was wanted. 
\end{proof}

\section{Successive Minima}
Let \(\func{\lambda_i}{\Lambda}\) be the minimum norm of the longest vector among any set \(i\) linearly independent vectors in \(\Lambda\). 
\begin{equation*}
    \func{\lambda_i}{\Lambda} = \min_{\substack{\set{y_1, \dots, y_i} \\ \mathrm{lin \ indp}}} \max_{1 \leq j \leq i} \norm{y_j}
\end{equation*}
or equivalently 
\begin{equation*}
    \func{\lambda_i}{\Lambda} = \inf \set<r>{\dim \func{\vspan}{ \Lambda \cap \func{B_r}{0} }\geq i}
\end{equation*}
\begin{theorem}
    Let \(\Lambda\) be a littice of rank \(n\) with successive minima \(\func{\lambda_1}{\Lambda}, \dots, \func{\lambda_n}{\Lambda}\). There exists a set of linearly independent vectors \(v_1, \dots, v_n \in \Lambda\) such that \(\norm{v_i} = \func{\lambda_i}{\Lambda}\). 
\end{theorem}
\subsection{Lower bound on \(\lambda_1\)}
\begin{theorem}
    Let \(\func{\calL}{B}\) be a lattice, then
    \begin{equation*}
        \func{\lambda_1}{\func{\calL}{B}} \geq \min_j \norm{b_j^{\ast}}
    \end{equation*}
    and more generally 
    \begin{equation*}
        \func{\lambda_i}{\func{\calL}{B}} \geq \min){j \geq i} \norm{b_j^{\ast}}
    \end{equation*}
\end{theorem}
\begin{proof}
    Let \(x \in \Integers^n\), we will show that \(\norm{Bx} \geq \min_j \norm{b_j^{\ast}}\) for all \(x \in \Integers^n\). Note that, for any \(i\) we have
    \begin{equation*}
        \abs{\angleBracket{Bx, b_i^{\ast}}} = \abs{\sum_{j = 1}^n x_j\angleBracket{b_j , b_i^{\ast}}} = \abs{\sum_{j = i}^n x_j\angleBracket{b_j , b_i^{\ast}}} 
    \end{equation*}
    Let \(i\) be the largest indext that \(x_i \neq 0\). That is, for all \(j > i\), \(x_j = 0\). Thus 
    \begin{equation*}
        \abs{\angleBracket{Bx, b_i^{\ast}}} = \abs{x_i\angleBracket{b_i , b_i^{\ast}}} = \abs{x_i} \norm{b_i^{\ast}}^2 \leq \norm{b_i^{\ast}}^2
    \end{equation*}
    Moreover, by Cauchy-Schwarz inequality 
    \begin{equation*}
        \abs{\angleBracket{Bx, b_i^{\ast}}} \leq \norm{Bx} \norm{b_i^{\ast}}
    \end{equation*}
    ans hence 
    \begin{equation*}
        \norm{Bx} \geq \norm{b_i^{\ast}} \geq \min_j \norm{b_j^{\ast}}
    \end{equation*}
    which was what was wanted.
\end{proof}

\begin{corollary}
    For all lattices \(\Lambda\), there exists a constant \(\func{\epsilon}{\Lambda} > 0\) such that for all \(x,y \in \Lambda\) we have 
    \begin{equation*}
        \norm{x - y} \geq \func{\epsilon}{\Lambda}
    \end{equation*}
\end{corollary}
\begin{proof}
    Note that \(x -y \in \Lambda\) then, let \(\func{\epsilon}{\Lambda} = \func{\lambda_1}{\Lambda}\).
\end{proof}

\begin{theorem}
    A set \(\Lambda \subset \Reals^m\) is a lattice if and only if it is a discrete additive subgroup of \(\Reals^m\).
\end{theorem}
\section{Minkowski's Theorems}
\begin{theorem}[Blichfeld theorem]
    For any \(\Lambda\) and for any measurable set \(S \subset \vspan \Lambda\), if \(S\) has a volume \(\func{\vol}{S} > \det \Lambda\), then there exists two distinct points \(z_1,z_2 \in S\) such that \(z_1 - z_2 \in \Lambda\).    
\end{theorem}

\begin{theorem}[Convex body theorem]
    For any lattice \(\Lambda\) of rank \(n\) and any convext set \(S \subset \vspan \Lambda\) symmetric about the origin, if \(\func{\vol}{S} > 2^n \det\Lambda\), then \(S\) contains a non-zero lattice point.    
\end{theorem}

\begin{theorem}[Minkowski's first theorem]
    For any lattice \(\Lambda\),
    \begin{equation*}
        \func{\lambda_1}{\Lambda} \leq \sqrt{n} \bracket{\det \Lambda}^{\frac{1}{n}}
    \end{equation*}
\end{theorem}

\begin{theorem}[Minkowski's second theorem]
    For any lattice \(\Lambda\) of rank \(n\) under the \(l_2\) norm
    \begin{equation*}
        \bracket{\prod_{i=1}^n\func{\lambda_i}{\Lambda}}^{\frac{1}{n}} \leq \sqrt{n} \bracket{\det \Lambda}^{\frac{1}{n}}
    \end{equation*}
\end{theorem}