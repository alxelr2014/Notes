\chapter{Asymptotic Equipartition Property}
\section{AEP and the typical set}
\begin{example}
    Suppose \(X_i \sim \func{\Bernoulli}{p}\) are i.i.d. then 
    \begin{align*}
        \prob{X_1 + \dots +  X_n = k} &= \binom{n}{k} p^k \bracket{1 - p}^{n-k}\\
        &\simeq \dfrac{\bracket{\frac{n}{e}}^n }{ \bracket{\frac{k}{e}}^k \bracket{\frac{n - k}{e}}^{n - k}} p^k \bracket{1 - p}^{n-k} \\
        &= \bracket{\dfrac{n}{k}}^k \bracket{\dfrac{n }{n - k}}^{n - k} p^k \bracket{1 - p}^{n-k}
        \intertext{Let \(k = np\)}
        &= p^{-np} \bracket{ 1 - p}^{-n (1 - p)} p^{np} \bracket{1 - p}^{n (1 - p)}
    \end{align*}
\end{example}

\begin{theorem}[AEP theorem]
    Suppose  \(X_1 ,X_2,  \dots  \sim \func{f}{X}\) are i.i.d. then 
    \begin{equation*}
        -\dfrac{1}{n} \lg \func{f}{X_1 , \dots , X_n} \xrightarrow{\Probability, a.s.} \func{H}{X}
    \end{equation*}
\end{theorem}
\begin{proof}
    By the weak/strong law of large numbers
    \begin{align*}
        -\dfrac{1}{n} \lg \func{f}{X_1 , \dots , X_n} &= - \dfrac{1}{n} \func{\lg}{\func{f}{X_1} \dots \func{f}{X_n}}\\
        &= - \dfrac{1}{n} \sum \lg \func{f}{X_i}\\
        &\xrightarrow{\Probability, a.s.} - \expected{\lg \func{f}{X}} = \func{H}{X}
    \end{align*}
\end{proof}

\begin{definition}
    A typical set \(A_{\epsilon}^{(n)}\) 
    \begin{equation*}
        A_{\epsilon}^{(n)} = \set< (x_1 , \dots , x_n)> { \abs{ -\dfrac{1}{n} \lg \func{f}{X_1 , \dots , X_n}} - \func{H}{X} < \epsilon}
    \end{equation*}
    hence if \(\bar{x} \in A_{\epsilon}^{(n)}\) then 
    \begin{equation*}
        2^{-n (\func{H}{X} + \epsilon)} \leq \prob{\bar{x}} \leq 2^{-n (\func{H}{X} - \epsilon)}
    \end{equation*}
\end{definition}

\begin{proposition}
    \begin{enumerate}
        \item For sufficiently large \(n\)
        \begin{equation*}
            \prob{\bar{x} \in A^{(n)}_{\epsilon}} \geq 1 -\epsilon
        \end{equation*}
        \item For all \(n\) 
        \begin{equation*}
            \abs{A_{\epsilon}^{(n)}} \leq 2^{n (\func{H}{X} + \epsilon)}
        \end{equation*}
        and for sufficiently large \(n\)
        \begin{equation*}
            \abs{A_{\epsilon}^{(n)}} \geq \bracket{1 - \epsilon} 2^{n (\func{H}{X} - \epsilon)}
        \end{equation*}
    \end{enumerate}
\end{proposition}

\begin{proof}
    \begin{enumerate}
        \item By the AEP theorem there exists \(N\) such that for all \(n \geq N\)
        \begin{equation*}
            \prob{\abs{-\dfrac{1}{n} \lg \func{f}{X_1 , \dots , X_n} - \func{H}{X}} < \epsilon} \geq 1 - \epsilon
        \end{equation*}
        which means for sufficiently large \(n\) 
        \begin{equation*}
            \prob{\bar{x} \in A^{(n)}_{\epsilon}} \geq 1 -\epsilon
        \end{equation*}
        \item For each \(\bar{x} \in A_{\epsilon}^{(n)}\) 
        \begin{equation*}
            2^{-n (\func{H}{X} + \epsilon)} \leq \prob{\bar{x}}
        \end{equation*}
        therfore 
        \begin{equation*}
            \abs{A_{\epsilon}^{(n)}} 2^{-n (\func{H}{X} + \epsilon)} \leq \prob{\bar{x} \in A^{(n)}_{\epsilon}} \leq 1
        \end{equation*}
        and similarly from the last result, for sufficiently large \(n\)
        \begin{equation*}
            1 - \epsilon \leq \prob{\bar{x} \in A^{(n)}_{\epsilon}} \leq \abs{A_{\epsilon}^{(n)}} 2^{-n (\func{H}{X} - \epsilon)}
        \end{equation*}
    \end{enumerate}
\end{proof}

By AEP we prove the compression theorem, that is, there exists \(C\) such that \(\func{L}{C} = \func{H}{X}\). This code works as follow 
\begin{itemize}
    \item Since there are at most \(2^{n (\func{H}{X} + \epsilon)}\) sequences in \(A^{(n)}_{\epsilon}\) then we can code them all with codewords of length \(n (\func{H}{X} + \epsilon) + 1\) bits. 
    \item There are at most \(\abs{\calX}^n\) sequnces not in \(A^{(n)}_{\epsilon}\) and hence we can code them with codewords of length \(n\lg \abs{\calX} + 1\) bits. 
    \item To be able uniquely decode typical sequences from atypical ones, prefix a \(1\) for typicals and prefix a \(0\) for atypical sequences. 
\end{itemize}
The average length of the above coding scheme is 
\begin{align*}
    \func{L}{C} &\leq \sum_{\bar{x} \in A_{\epsilon}^{(n)}} \prob{\bar{x}} \bracket{n (\func{H}{X} + \epsilon) + 2} + \sum_{\bar{x} \notin A_{\epsilon}^{(n)}} \prob{\bar{x}} \bracket{n \lg \abs{\calX} + 2} \\
    &= \bracket{n (\func{H}{X} + \epsilon) + 2} \bracket{1 -\prob{\bar{x} \notin A_{\epsilon}^{(n)}}} + \bracket{n \lg \abs{\calX} + 2} \prob{\bar{x} \notin A_{\epsilon}^{(n)}} \\ 
    &= n\func{H}{X} + n\epsilon + 2 +  n\bracket{ \lg \calX - \func{H}{X} - \epsilon}  \prob{\bar{x} \notin A_{\epsilon}^{(n)}} 
    \intertext{Let \(n\) be sufficiently large that \(\prob{\bar{x} \notin A_{\epsilon}^{(n)}} \leq \epsilon\)}
    &\leq n\func{H}{X} + n\epsilon + 2 + n\bracket{ \lg \calX - \func{H}{X} - \epsilon} \epsilon\\
    &= n (\func{H}{X} + \epsilon') \qquad \epsilon' = \epsilon + \dfrac{2}{n} + \epsilon \lg \calX - \epsilon \func{H}{X} - \epsilon^2
\end{align*}
Where \(\epsilon'\) can be made arbitrarily small and thus 
\begin{equation*}
    \func{L}{C} \xrightarrow[n \to \infty]{\epsilon \to 0} n \func{H}{X}
\end{equation*}
\section{High-probability set}
It is clear that \(A_{\epsilon}^{(n)}\) is a fairly small set with high probability. We will argue that it has the about as small as the smallest set with high probability. 
\begin{definition}
    Let \(B_{\epsilon}^{(n)}\) be the smallest set such that 
    \begin{equation*}
        \prob{\bar{x} \in B_{\epsilon}^(n)} \leq 1 - \epsilon
    \end{equation*}
\end{definition}

\begin{theorem}
    Let \(X_1 , \dots \sim \func{f}{X}\) be i.i.d and (condition on \(\epsilon\)) then for any \(\delta > 0\) 
    \begin{equation*}
        \dfrac{1}{n} \lg \abs{B_{\epsilon}^{(n)}} > \func{H}{X} - \delta
    \end{equation*}
    for sufficiently large \(n\). Therefore, \(B_{\epsilon}^{(n)}\) contains at least \(2^{n \func{H}{X}}\) elements hence \(A_{\epsilon}^{n}\) has about the same number elements as the high-probability set.
\end{theorem}

\section{Stochastic Processes}
For the general case when \(X_i\) are not independent, we can assume they form an stochastic process. A stationary stochastic process is invariant to time shifts 
\begin{equation*}
    \func{f}{x_1, \dots, x_n ; t_1 , \dots , t_n} = \func{f}{x_1, \dots, x_n ; t_1 + c , \dots , t_n + c}
\end{equation*}
\begin{definition} [Entropy rate]
    The entropy of a stochastic process \(\set{X_i}\) is 
    \begin{equation*}
        \func{H}{\calX} = \lim_{n \to \infty} \dfrac{1}{n} \func{H}{X_1, \dots , X_n}
    \end{equation*}
    when the limit exists. Another definition for entropy rate is 
    \begin{equation*}
        \func{H'}{\calX} =  \lim_{n \to \infty}  \func{H}{X_n |X_1, \dots , X_{n-1}}
    \end{equation*}
    when the limit exists. Note that the first denotes the per symbol entropy and the second one denotes the entropy of the last symbol given its past. 
\end{definition}
\begin{theorem}
    For discrete stationary stochastic processes both \(\func{H}{\calX}\) and \(\func{H'}{\calX}\) exist and they are equal. 
\end{theorem}

\begin{proof}
    Since \(X_i\) are stationary then \(b_n = \func{H}{X_n | X_1 , \dots , X_{n-1}}\)
    \begin{equation*}
        \func{H}{X_{n + 1} | X_1 , \dots , X_n} \leq \func{H}{X_{n+1}| X_2 , \dots , X_n} = \func{H}{X_n | X_1 , \dots , X_{n-1}}
    \end{equation*}
    is non-increasing and bounded from below by \(0\) therefore, it converges. Moreover, 
    \begin{align*}
       \dfrac{1}{n} \func{H}{X_1, \dots,  X_n} &= \dfrac{1}{n} \squareBracket{\func{H}{X_1} + \func{H}{X_2 | X_1} + \dots + \func{H}{X_n | X_1, \dots, X_{n-1}}}\\
       &= \dfrac{1}{n} \bracket{b_1 + \dots  + b_n} \to \inf b_n \\
       \implies& \func{H}{\calX} = \func{H'}{\calX}
    \end{align*}

\end{proof}

Therefore, for stationary stochastic processes we can show the AEP 
\begin{equation*}
    -\dfrac{1}{n} \lg \func{f}{X_1, \dots , X_n} \xrightarrow{\Probability} \func{H}{\calX}
\end{equation*}
and from this we can define typical set for such processes, which has a size of \(2^{n \func{H}{\calX}}\) and probability of close to \(1\). Then, we can show that there is code which one average uses \(\func{H}{\calX}\) bits. 